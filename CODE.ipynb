{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkarshBhatia/LeafC/blob/main/CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uhNVWSB7l_RV"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Specify the path to your ZIP file\n",
        "zip_file_path = '/content/Training-20251026T192946Z-1-001.zip'\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "# If not provided, it extracts to the current working directory\n",
        "extract_to_directory = 'extracted_contents'\n",
        "\n",
        "with ZipFile(zip_file_path, 'r') as zip_object:\n",
        "    zip_object.extractall(extract_to_directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XYZ = input(\"ENTER BASEPATH OF ALL 5 CLASSES TRAINING FOLDER\")\n",
        "ERT = input(\"ENTER PATH OF ANY ONE LEAF IMAGE SAMPLE CHOSEN FROM KNOWN/UNKNOWN FOLDER\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op8BBZ59vtfL",
        "outputId": "864d44d7-22da-4727-a931-bddc2a87be75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENTER BASEPATH OF ALL 5 CLASSES TRAINING FOLDER/content/extracted_contents/Training\n",
            "ENTER PATH OF ANY ONE LEAF IMAGE SAMPLE CHOSEN FROM KNOWN/UNKNOWN FOLDER/content/extracted_contents/Training/jatropha/0006_0026.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.svm import OneClassSVM, SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "\n",
        "# ============== Noise control ==============\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='skimage')\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "# ============== Feature extraction ==============\n",
        "def segment_leaf(image_path):\n",
        "    \"\"\"Segments the leaf from the background.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"FATAL: Image not found at {image_path}. Please check the path.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, binary_mask = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        leaf_mask = np.zeros_like(gray, dtype=np.uint8)\n",
        "        cv2.drawContours(leaf_mask, [largest_contour], -1, 255, cv2.FILLED)\n",
        "        return leaf_mask, image\n",
        "    return np.zeros_like(gray, dtype=np.uint8), image\n",
        "\n",
        "def calculate_morphological_features(leaf_mask):\n",
        "    \"\"\"Calculates area, perimeter, aspect ratio, and circularity.\"\"\"\n",
        "    contours, _ = cv2.findContours(leaf_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return {'area': 0, 'perimeter': 0, 'aspect_ratio': 0, 'circularity': 0}\n",
        "\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(cnt)\n",
        "    perimeter = cv2.arcLength(cnt, True)\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "    aspect_ratio = float(w) / h if h != 0 else 0\n",
        "    circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0\n",
        "\n",
        "    return {'area': area, 'perimeter': perimeter, 'aspect_ratio': aspect_ratio, 'circularity': circularity}\n",
        "\n",
        "def calculate_texture_features(image, leaf_mask):\n",
        "    \"\"\"Calculates contrast, correlation, and energy.\"\"\"\n",
        "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    masked_gray = cv2.bitwise_and(gray_img, gray_img, mask=leaf_mask)\n",
        "    masked_gray_norm = cv2.normalize(masked_gray, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "    try:\n",
        "        glcm = graycomatrix(masked_gray_norm, distances=[1], angles=[0],\n",
        "                            levels=256, symmetric=True, normed=True)\n",
        "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
        "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "    except ValueError:\n",
        "        return {'contrast': 0, 'correlation': 0, 'energy': 0}\n",
        "\n",
        "    return {'contrast': contrast, 'correlation': correlation, 'energy': energy}\n",
        "\n",
        "def extract_all_features(image_path):\n",
        "    \"\"\"Combines all feature extraction steps for a single image.\"\"\"\n",
        "    try:\n",
        "        leaf_mask, image = segment_leaf(image_path)\n",
        "        if np.sum(leaf_mask) == 0:\n",
        "            print(f\"Warning: No leaf detected in {image_path}. Returning zero features.\")\n",
        "            return [0] * 7\n",
        "\n",
        "        morph = calculate_morphological_features(leaf_mask)\n",
        "        tex = calculate_texture_features(image, leaf_mask)\n",
        "\n",
        "        return [\n",
        "            morph['area'], morph['perimeter'], morph['aspect_ratio'],\n",
        "            morph['circularity'], tex['contrast'], tex['correlation'], tex['energy']\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {image_path}: {e}\")\n",
        "        return [0] * 7\n",
        "\n",
        "# ============== Data loading (ONE class per call) ==============\n",
        "def process_training_data(folder_path):\n",
        "    \"\"\"Processes all images inside ONE class folder.\"\"\"\n",
        "    class_data = {}\n",
        "    class_name = os.path.basename(folder_path.rstrip(os.sep))\n",
        "    class_data[class_name] = []\n",
        "\n",
        "    print(f\"Processing training data for class: {class_name}\")\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        raise FileNotFoundError(f\"Error: Folder not found -> {folder_path}\")\n",
        "\n",
        "    image_files = [f for f in os.listdir(folder_path)\n",
        "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    if not image_files:\n",
        "        raise RuntimeError(f\"No images found in {folder_path}\")\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "        features = extract_all_features(img_path)\n",
        "        if sum(features) > 0:\n",
        "            class_data[class_name].append(features)\n",
        "\n",
        "    print(f\"  -> {len(class_data[class_name])} images processed.\")\n",
        "    return class_data, [class_name]  # return class name as a list\n",
        "\n",
        "# ============== Training helpers ==============\n",
        "def train_one_class_models_per_folder(folder_paths, nu=0.3, gamma='auto'):\n",
        "    \"\"\"\n",
        "    Trains One-Class SVMs strictly one class at a time (each on its own folder).\n",
        "    Returns:\n",
        "        oc_models: {class_name: OneClassSVM}\n",
        "        oc_scalers: {class_name: StandardScaler}\n",
        "        class_names: [class_name, ...] in discovered order\n",
        "    \"\"\"\n",
        "    oc_models, oc_scalers, class_names = {}, {}, []\n",
        "\n",
        "    print(\"\\nTraining One-Class SVMs (per class)...\")\n",
        "    for class_folder in folder_paths:\n",
        "        cd, cn = process_training_data(class_folder)  # one class per call\n",
        "        cname = cn[0]\n",
        "        X = np.array(cd[cname])\n",
        "\n",
        "        if X.shape[0] < 2:\n",
        "            raise RuntimeError(f\"Class '{cname}' needs >=2 samples; got {X.shape[0]}.\")\n",
        "\n",
        "        scaler = StandardScaler().fit(X)\n",
        "        Xs = scaler.transform(X)\n",
        "\n",
        "        oc = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma).fit(Xs)\n",
        "\n",
        "        oc_models[cname] = oc\n",
        "        oc_scalers[cname] = scaler\n",
        "        class_names.append(cname)\n",
        "        print(f\"  - {cname}: {X.shape[0]} samples\")\n",
        "\n",
        "    return oc_models, oc_scalers, class_names\n",
        "\n",
        "def collect_all_classes(folder_paths):\n",
        "    \"\"\"\n",
        "    Aggregates features from all class folders into one dict for multi-class training.\n",
        "    Returns:\n",
        "        class_data: {class_name: [feature_vec, ...]}\n",
        "        class_names: [class_name, ...]\n",
        "    \"\"\"\n",
        "    all_class_data, all_class_names = {}, []\n",
        "    for p in folder_paths:\n",
        "        cd, cn = process_training_data(p)  # one class\n",
        "        cname = cn[0]\n",
        "        all_class_data[cname] = cd[cname]\n",
        "        all_class_names.append(cname)\n",
        "    return all_class_data, all_class_names\n",
        "\n",
        "def train_multiclass_svm(class_data, class_names, kernel='rbf', gamma='auto', ovo_or_ovr='ovo'):\n",
        "    \"\"\"\n",
        "    Trains a single multi-class SVM over all classes.\n",
        "    SVC is OvO by default; set decision_function_shape='ovr' for OvR.\n",
        "    Returns: mc_svm, mc_scaler\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    name_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "    for cname in class_names:\n",
        "        feats = class_data.get(cname, [])\n",
        "        for feat in feats:\n",
        "            X.append(feat)\n",
        "            y.append(name_to_idx[cname])\n",
        "\n",
        "    if len(set(y)) < 2:\n",
        "        raise RuntimeError(\"Need at least 2 classes with data to train multi-class SVM.\")\n",
        "\n",
        "    X = np.array(X); y = np.array(y)\n",
        "    mc_scaler = StandardScaler().fit(X)\n",
        "    Xs = mc_scaler.transform(X)\n",
        "\n",
        "    decision_shape = 'ovr' if ovo_or_ovr.lower() == 'ovr' else 'ovo'\n",
        "    mc_svm = SVC(kernel=kernel, gamma=gamma, probability=True,\n",
        "                 decision_function_shape=decision_shape).fit(Xs, y)\n",
        "\n",
        "    print(\"\\nMulti-Class SVM trained on:\",\n",
        "          {c: len(class_data[c]) for c in class_names})\n",
        "    return mc_svm, mc_scaler\n",
        "# ============== Inference ==============\n",
        "def classify_with_gate(image_path, oc_models, oc_scalers, mc_svm, mc_scaler, class_names):\n",
        "    \"\"\"\n",
        "    1) Gate with per-class One-Class SVMs (trained one-at-a-time).\n",
        "    2) If any OC accepts, do final multi-class classification over all classes.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Classifying {os.path.basename(image_path)} ---\")\n",
        "    feats = extract_all_features(image_path)\n",
        "    if sum(feats) == 0:\n",
        "        print(\"Result: Could not extract features from the image.\")\n",
        "        return\n",
        "\n",
        "    x = np.array(feats).reshape(1, -1)\n",
        "\n",
        "    print(\"Step 1: One-Class SVM gate...\")\n",
        "    accepted = []\n",
        "    for cname, oc in oc_models.items():\n",
        "        xs = oc_scalers[cname].transform(x)\n",
        "        if oc.predict(xs)[0] == 1:\n",
        "            accepted.append(cname)\n",
        "\n",
        "    if not accepted:\n",
        "        print(\"\\nResult: UNKNOWN (rejected by all One-Class models).\")\n",
        "        return\n",
        "\n",
        "    print(f\"  Accepted by: {accepted}\")\n",
        "\n",
        "    print(\"\\nStep 2: Multi-Class SVM over all classes...\")\n",
        "    x_mc = mc_scaler.transform(x)\n",
        "    idx = mc_svm.predict(x_mc)[0]\n",
        "    final_name = class_names[idx]\n",
        "    print(f\"\\n>>> Final Result: {final_name}\")\n",
        "\n",
        "# ============== Main ==============\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: set this to the parent folder that contains your 5 class subfolders\n",
        "    base_path = XYZ\n",
        "\n",
        "    # TODO: make sure these names EXACTLY match your directory names\n",
        "    class_folder_names = [\n",
        "        \"alstonia\",\n",
        "        \"chinar\",\n",
        "        \"jatropha\",\n",
        "        \"mango\",\n",
        "        \"pongamia\"\n",
        "    ]\n",
        "    folder_paths = [os.path.join(base_path, n) for n in class_folder_names]\n",
        "\n",
        "    print(\"Folder check:\")\n",
        "\n",
        "\n",
        "    # TODO: set the path to a test image you want to classify\n",
        "    TEST_IMAGE_PATH = ERT\n",
        "\n",
        "    try:\n",
        "        # One-Class SVMs: train one class at a time (your rule)\n",
        "        oc_models, oc_scalers, class_names = train_one_class_models_per_folder(\n",
        "            folder_paths, nu=0.1, gamma='auto'\n",
        "        )\n",
        "\n",
        "        # Multi-Class SVM: trained on all classes together\n",
        "        class_data_mc, class_names_mc = collect_all_classes(folder_paths)\n",
        "\n",
        "        # Keep order consistent with OC training (reindex if needed)\n",
        "        if class_names != class_names_mc:\n",
        "            # Reorder class_data_mc to follow class_names order\n",
        "            class_data_mc = {name: class_data_mc[name] for name in class_names if name in class_data_mc}\n",
        "\n",
        "        mc_svm, mc_scaler = train_multiclass_svm(\n",
        "            class_data_mc, class_names, kernel='rbf', gamma='auto', ovo_or_ovr='ovo'\n",
        "        )\n",
        "\n",
        "        # Inference\n",
        "        classify_with_gate(\n",
        "            image_path=TEST_IMAGE_PATH,\n",
        "            oc_models=oc_models,\n",
        "            oc_scalers=oc_scalers,\n",
        "            mc_svm=mc_svm,\n",
        "            mc_scaler=mc_scaler,\n",
        "            class_names=class_names\n",
        "        )\n",
        "\n",
        "    except (FileNotFoundError, NotADirectoryError, RuntimeError) as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")\n",
        "        print(\"Please ensure your paths, folder names, and data are correct and try again.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "2d8humZkoA3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981c9a8e-3f57-49d4-c9a8-6429273ff695"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder check:\n",
            "\n",
            "Training One-Class SVMs (per class)...\n",
            "Processing training data for class: alstonia\n",
            "  -> 200 images processed.\n",
            "  - alstonia: 200 samples\n",
            "Processing training data for class: chinar\n",
            "  -> 200 images processed.\n",
            "  - chinar: 200 samples\n",
            "Processing training data for class: jatropha\n",
            "  -> 200 images processed.\n",
            "  - jatropha: 200 samples\n",
            "Processing training data for class: mango\n",
            "  -> 200 images processed.\n",
            "  - mango: 200 samples\n",
            "Processing training data for class: pongamia\n",
            "  -> 200 images processed.\n",
            "  - pongamia: 200 samples\n",
            "Processing training data for class: alstonia\n",
            "  -> 200 images processed.\n",
            "Processing training data for class: chinar\n",
            "  -> 200 images processed.\n",
            "Processing training data for class: jatropha\n",
            "  -> 200 images processed.\n",
            "Processing training data for class: mango\n",
            "  -> 200 images processed.\n",
            "Processing training data for class: pongamia\n",
            "  -> 200 images processed.\n",
            "\n",
            "Multi-Class SVM trained on: {'alstonia': 200, 'chinar': 200, 'jatropha': 200, 'mango': 200, 'pongamia': 200}\n",
            "\n",
            "--- Classifying 0006_0026.JPG ---\n",
            "Step 1: One-Class SVM gate...\n",
            "  Accepted by: ['alstonia', 'chinar', 'jatropha', 'mango', 'pongamia']\n",
            "\n",
            "Step 2: Multi-Class SVM over all classes...\n",
            "\n",
            ">>> Final Result: chinar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.svm import OneClassSVM, SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "# Quiet minor warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='skimage')\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "# ===================== Feature extraction =====================\n",
        "def segment_leaf(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"FATAL: Image not found at {image_path}\")\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        largest = max(contours, key=cv2.contourArea)\n",
        "        mask = np.zeros_like(gray, dtype=np.uint8)\n",
        "        cv2.drawContours(mask, [largest], -1, 255, cv2.FILLED)\n",
        "        return mask, image\n",
        "    return np.zeros_like(gray, dtype=np.uint8), image\n",
        "\n",
        "def calculate_morphological_features(mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return {'area': 0, 'perimeter': 0, 'aspect_ratio': 0, 'circularity': 0}\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(cnt)\n",
        "    per = cv2.arcLength(cnt, True)\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    ar = float(w) / h if h else 0\n",
        "    circ = (4 * np.pi * area) / (per ** 2) if per else 0\n",
        "    return {'area': area, 'perimeter': per, 'aspect_ratio': ar, 'circularity': circ}\n",
        "\n",
        "def calculate_texture_features(image, mask):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    masked = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "    norm = cv2.normalize(masked, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    try:\n",
        "        glcm = graycomatrix(norm, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "        return {\n",
        "            'contrast':   graycoprops(glcm, 'contrast')[0, 0],\n",
        "            'correlation':graycoprops(glcm, 'correlation')[0, 0],\n",
        "            'energy':     graycoprops(glcm, 'energy')[0, 0],\n",
        "        }\n",
        "    except ValueError:\n",
        "        return {'contrast': 0, 'correlation': 0, 'energy': 0}\n",
        "\n",
        "def extract_all_features(image_path):\n",
        "    try:\n",
        "        mask, img = segment_leaf(image_path)\n",
        "        if np.sum(mask) == 0:\n",
        "            # print(f\"Warning: No leaf detected in {image_path}.\")\n",
        "            return None\n",
        "        morph = calculate_morphological_features(mask)\n",
        "        tex = calculate_texture_features(img, mask)\n",
        "        return [\n",
        "            morph['area'], morph['perimeter'], morph['aspect_ratio'],\n",
        "            morph['circularity'], tex['contrast'], tex['correlation'], tex['energy']\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===================== Data loading =====================\n",
        "def load_all_data(parent_dir):\n",
        "    \"\"\"Scan parent_dir for class subfolders, build X, y, class_names.\"\"\"\n",
        "    X, y, class_names = [], [], []\n",
        "    if not os.path.isdir(parent_dir):\n",
        "        raise NotADirectoryError(f\"FATAL: '{parent_dir}' not found.\")\n",
        "    class_dirs = sorted([d for d in os.listdir(parent_dir)\n",
        "                         if os.path.isdir(os.path.join(parent_dir, d))])\n",
        "    if not class_dirs:\n",
        "        raise NotADirectoryError(f\"FATAL: No class subdirectories in '{parent_dir}'.\")\n",
        "    print(\"Loading data...\")\n",
        "    for idx, cname in enumerate(class_dirs):\n",
        "        cdir = os.path.join(parent_dir, cname)\n",
        "        class_names.append(cname)\n",
        "        imgs = [os.path.join(cdir, f) for f in os.listdir(cdir)\n",
        "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        print(f\"  - {cname}: {len(imgs)} files\")\n",
        "        for p in imgs:\n",
        "            feats = extract_all_features(p)\n",
        "            if feats is not None:\n",
        "                X.append(feats); y.append(idx)\n",
        "    if not X:\n",
        "        raise RuntimeError(\"No valid images found after feature extraction.\")\n",
        "    print(f\"Loaded {len(X)} samples from {len(class_names)} classes.\")\n",
        "    return np.array(X), np.array(y), class_names\n",
        "\n",
        "# ===================== Training =====================\n",
        "def train_one_class_models(X_train, y_train, class_names, nu=0.3, gamma='auto'):\n",
        "    \"\"\"Train OC-SVM per class on that class's subset only.\"\"\"\n",
        "    oc_models, oc_scalers = {}, {}\n",
        "    print(\"\\nTraining One-Class SVMs (per class)...\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        Xi = X_train[y_train == i]\n",
        "        if Xi.shape[0] < 2:\n",
        "            print(f\"  ! Skipping '{cname}' (<2 samples)\")\n",
        "            continue\n",
        "        scaler = StandardScaler().fit(Xi)\n",
        "        Xs = scaler.transform(Xi)\n",
        "        oc = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma).fit(Xs)\n",
        "        oc_models[cname] = oc\n",
        "        oc_scalers[cname] = scaler\n",
        "        print(f\"  - {cname}: {Xi.shape[0]} samples\")\n",
        "    if not oc_models:\n",
        "        raise RuntimeError(\"No OC models trained; not enough data per class.\")\n",
        "    return oc_models, oc_scalers\n",
        "\n",
        "def train_multiclass_svm(X_train, y_train, kernel='rbf', gamma='auto'):\n",
        "    \"\"\"Train a single multi-class SVM (OvO default).\"\"\"\n",
        "    print(\"\\nTraining Multi-Class SVM...\")\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    Xs = scaler.transform(X_train)\n",
        "    clf = SVC(kernel=kernel, gamma=gamma, probability=True).fit(Xs, y_train)\n",
        "    print(\"Multi-Class SVM trained.\")\n",
        "    return clf, scaler\n",
        "\n",
        "# ===================== Evaluation (OC gate + Multi) =====================\n",
        "def evaluate_model(X_data, y_data, oc_models, oc_scalers, mc_svm, mc_scaler, class_names):\n",
        "    \"\"\"\n",
        "    OC gate: if no OC accepts -> UNKNOWN; else final label from multi-class SVM.\n",
        "    UNKNOWN index = len(class_names) (added only for report).\n",
        "    \"\"\"\n",
        "    print(\"\\nEvaluating (OC gate -> Multi)...\")\n",
        "    UNKNOWN_IDX = len(class_names)\n",
        "    y_pred = []\n",
        "\n",
        "    for feats in X_data:\n",
        "        x = feats.reshape(1, -1)\n",
        "        accepted = False\n",
        "        # Gate with all OC models\n",
        "        for cname, oc in oc_models.items():\n",
        "            xs = oc_scalers[cname].transform(x)\n",
        "            if oc.predict(xs)[0] == 1:\n",
        "                accepted = True\n",
        "                break\n",
        "        if not accepted:\n",
        "            y_pred.append(UNKNOWN_IDX)\n",
        "            continue\n",
        "        # Multi-class decision\n",
        "        x_mc = mc_scaler.transform(x)\n",
        "        y_pred.append(int(mc_svm.predict(x_mc)[0]))\n",
        "\n",
        "    labels = list(range(len(class_names))) + [UNKNOWN_IDX]\n",
        "    names = class_names + [\"UNKNOWN\"]\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_data, y_pred, labels=labels, target_names=names, zero_division=0))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    base_path = XYZ  # parent folder\n",
        "\n",
        "    # Five separate class paths\n",
        "    alstonia_path = os.path.join(base_path, \"alstonia \")\n",
        "    chinar_path   = os.path.join(base_path, \"chinar\")\n",
        "    jatropha_path = os.path.join(base_path, \"jatropha\")\n",
        "    mango_path    = os.path.join(base_path, \"mango\")\n",
        "    pongamia_path  = os.path.join(base_path, \"pongamia\")  # ensure exact spelling\n",
        "\n",
        "    # Combined list (useful for sanity checks or per-class ops if needed)\n",
        "    folder_paths = [alstonia_path, chinar_path, jatropha_path, mango_path, pongamia_path]\n",
        "\n",
        "    # Sanity print\n",
        "    print(\"Folder check:\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Load everything from the parent (multi-class dataset)\n",
        "        X, y, class_names = load_all_data(base_path)\n",
        "\n",
        "        # Split for evaluation\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.20, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Train One-Class models strictly per class\n",
        "        oc_models, oc_scalers = train_one_class_models(\n",
        "            X_train, y_train, class_names, nu=0.1, gamma='auto'\n",
        "        )\n",
        "\n",
        "        # Train Multi-Class model over all classes together\n",
        "        mc_svm, mc_scaler = train_multiclass_svm(X_train, y_train, kernel='rbf', gamma='auto')\n",
        "\n",
        "        # Evaluate on the hold-out test set (UNKNOWN if OC gate rejects)\n",
        "        evaluate_model(X_test, y_test, oc_models, oc_scalers, mc_svm, mc_scaler, class_names)\n",
        "\n",
        "    except (FileNotFoundError, NotADirectoryError, RuntimeError) as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPZdHYAMNvH3",
        "outputId": "15b2ecb7-f899-40d0-8241-ac76954a2911"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder check:\n",
            "Loading data...\n",
            "  - .ipynb_checkpoints: 0 files\n",
            "  - alstonia: 200 files\n",
            "  - chinar: 200 files\n",
            "  - jatropha: 200 files\n",
            "  - mango: 200 files\n",
            "  - pongamia: 200 files\n",
            "Loaded 1000 samples from 6 classes.\n",
            "\n",
            "Training One-Class SVMs (per class)...\n",
            "  ! Skipping '.ipynb_checkpoints' (<2 samples)\n",
            "  - alstonia: 160 samples\n",
            "  - chinar: 160 samples\n",
            "  - jatropha: 160 samples\n",
            "  - mango: 160 samples\n",
            "  - pongamia: 160 samples\n",
            "\n",
            "Training Multi-Class SVM...\n",
            "Multi-Class SVM trained.\n",
            "\n",
            "Evaluating (OC gate -> Multi)...\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            ".ipynb_checkpoints       0.00      0.00      0.00         0\n",
            "          alstonia       0.47      0.23      0.31        40\n",
            "            chinar       0.46      0.65      0.54        40\n",
            "          jatropha       0.45      0.35      0.39        40\n",
            "             mango       0.75      0.75      0.75        40\n",
            "          pongamia       0.68      0.70      0.69        40\n",
            "           UNKNOWN       0.00      0.00      0.00         0\n",
            "\n",
            "          accuracy                           0.54       200\n",
            "         macro avg       0.40      0.38      0.38       200\n",
            "      weighted avg       0.56      0.54      0.54       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}